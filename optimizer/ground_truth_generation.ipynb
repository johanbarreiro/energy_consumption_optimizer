{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T19:14:58.373246Z",
     "start_time": "2024-07-09T19:14:58.367355Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\OneDrive\\Documents\\IE\\3. Trimestre\\Venture Lab & Capstone\\Capstone\\Tech side\\vl_optimizer\n"
     ]
    }
   ],
   "source": [
    "cd .. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75950d0a74b173",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f851ef68c04c520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T19:14:58.801876Z",
     "start_time": "2024-07-09T19:14:58.379145Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('data/processed_data/industrial_sites_processed/2024-07-09T19-25-47_industrial_site2_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfad0ad",
   "metadata": {},
   "source": [
    "Merge synthesized data into the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e93c5b48b26aba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T19:14:58.840087Z",
     "start_time": "2024-07-09T19:14:58.802969Z"
    }
   },
   "outputs": [],
   "source": [
    "def join_csv_on_time_column(directory='.'):\n",
    "    # Get all CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    \n",
    "    # Initialize an empty dataframe\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through each CSV file and merge them on the 'Time' column\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(directory, csv_file))  \n",
    "        \n",
    "        # Check if 'Time' column exists in the dataframe\n",
    "        if 'Time' not in df.columns:\n",
    "            print(f\"'Time' column not found in {csv_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Merge the dataframes\n",
    "        if merged_df.empty:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, df, on='Time', how='outer')\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Run the function and store the result\n",
    "merged_dataframe = join_csv_on_time_column(directory='data/synthesized_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788c87e",
   "metadata": {},
   "source": [
    "Create and save the hourly ground truth used for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4c90393aaf767a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T19:14:58.871387Z",
     "start_time": "2024-07-09T19:14:58.840709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the 24-hour period you want to optimize (for example, starting on 2024-07-01 00:00:00)\n",
    "start_date = '2023-06-01 00:00:00'\n",
    "end_date = '2023-07-01 00:00:00'\n",
    "\n",
    "# Filter the data for the chosen 24-hour period\n",
    "ground_truth = df[(df['Time'] >= start_date) & (df['Time'] < end_date)]\n",
    "\n",
    "ground_truth = pd.merge(ground_truth, merged_dataframe, on='Time', how='left')\n",
    "ground_truth['heat_index'] = ground_truth['heat_index_x']\n",
    "ground_truth['03 Chiller Group_Electric_Active Energy (kWh)'] = ground_truth['03 Chiller Group_Electric_Active Energy (kWh)_x']\n",
    "ground_truth = ground_truth.drop(columns=['heat_index_x', 'heat_index_y', '03 Chiller Group_Electric_Active Energy (kWh)_x', '03 Chiller Group_Electric_Active Energy (kWh)_y', 'total_consumption','target_consumption'])\n",
    "\n",
    "# Ensure that the data is sorted by timestamp and reset the index\n",
    "ground_truth = ground_truth.sort_values(by='Time').reset_index(drop=True)\n",
    "ground_truth.to_csv('optimizer/ground_truth/ground_truth_hourly.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e401f41",
   "metadata": {},
   "source": [
    "Create and save the hourly ground truth used for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f4630850803068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T19:14:58.880069Z",
     "start_time": "2024-07-09T19:14:58.872485Z"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth = ground_truth[['Time', 'energy_cost']]\n",
    "\n",
    "# Aggregate the data to daily\n",
    "ground_truth['Time'] = pd.to_datetime(ground_truth['Time'])\n",
    "ground_truth = ground_truth.set_index('Time')\n",
    "ground_truth = ground_truth.resample('D').sum()\n",
    "\n",
    "ground_truth.to_csv('optimizer/ground_truth/ground_truth_daily.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
