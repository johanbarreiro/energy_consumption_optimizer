{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T21:22:00.057815Z",
     "start_time": "2024-07-08T21:22:00.039262Z"
    }
   },
   "cell_type": "code",
   "source": "cd ..",
   "id": "e108da92ac113d4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johanbarreiro/Documents/GitHub\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T21:22:00.100496Z",
     "start_time": "2024-07-08T21:22:00.098615Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pyomo.environ import NonNegativeReals, NonNegativeIntegers\n",
    "from pyomo.environ import ConcreteModel, Var, Objective, Constraint, SolverFactory, Set, Param, NonNegativeReals, minimize"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read the parameter data:",
   "id": "2aae1724276517dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T21:22:00.223288Z",
     "start_time": "2024-07-08T21:22:00.101877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('optimizer/optimizer_input/parameters.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Choose the 24-hour period you want to optimize (for example, starting on 2024-07-01 00:00:00)\n",
    "start_date = '2023-06-01 00:00:00'\n",
    "end_date = '2023-06-02 00:00:00'\n",
    "\n",
    "# Filter the data for the chosen 24-hour period\n",
    "data = df[(df['Time'] >= start_date) & (df['Time'] < end_date)]\n",
    "\n",
    "# Ensure that the data is sorted by timestamp and reset the index\n",
    "data = data.sort_values(by='Time').reset_index(drop=True)\n",
    "\n",
    "# Check the filtered data\n",
    "data\n"
   ],
   "id": "b58b9ad5ea37a70a",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'optimizer/optimizer_input/parameters.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Read the CSV file into a DataFrame\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moptimizer/optimizer_input/parameters.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Choose the 24-hour period you want to optimize (for example, starting on 2024-07-01 00:00:00)\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/vl_optimizer_1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/vl_optimizer_1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/vl_optimizer_1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/vl_optimizer_1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/vl_optimizer_1/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'optimizer/optimizer_input/parameters.csv'"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a model:",
   "id": "fafefcb547960710"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the model\n",
    "model = ConcreteModel(name=\"Daily_Price_Optimizer\")\n",
    "\n",
    "# Display the model\n",
    "print(model)"
   ],
   "id": "c446ad3d703ec30f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Define Sets:** ",
   "id": "e410282e3f69d8ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the set of hours\n",
    "model.hours = Set(initialize=range(0, 24))"
   ],
   "id": "c5065603e361ab53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Define Parameters:**\n",
    "Parameters are values that are given to us, and we don’t have control over them."
   ],
   "id": "d35015d8aec453e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameters and initialize them with data from the CSV\n",
    "model.production_schedule = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['production_schedule'].to_dict())\n",
    "\n",
    "model.maintenance_status = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['maintenance_status'].to_dict())\n",
    "\n",
    "model.volume_production_waste = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['volume_production_waste'].to_dict())\n",
    "\n",
    "model.number_of_workers = Param(model.hours, within=NonNegativeIntegers, initialize=data.set_index('Hour')['number_of_workers'].to_dict())\n",
    "\n",
    "model.heat_index = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['heat_index'].to_dict())\n",
    "\n",
    "model.efficiency_adjusted_power = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['efficiency_adjusted_power'].to_dict())\n",
    "\n",
    "model.compressors_energy = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['compressor_consumption'].to_dict())\n",
    "\n",
    "model.operational_presence = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['operational_presence'].to_dict())\n",
    "\n",
    "model.fabric_in_chamber = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['fabric_in_chamber'].to_dict())\n",
    "\n",
    "model.testing_schedule = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['testing_schedule'].to_dict())\n",
    "\n",
    "model.workload = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['workload'].to_dict())\n",
    "\n",
    "model.technological_centers_energy = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['technological_centers_consumption'].to_dict())\n",
    "\n",
    "model.lightbulbs_active = Param(model.hours, within=NonNegativeIntegers, initialize=data.set_index('Hour')['lightbulbs_active'].to_dict())\n",
    "\n",
    "model.active_wall_plugs = Param(model.hours, within=NonNegativeIntegers, initialize=data.set_index('Hour')['active_wall_plugs'].to_dict())\n",
    "\n",
    "model.active_computers = Param(model.hours, within=NonNegativeIntegers, initialize=data.set_index('Hour')['active_computers'].to_dict())\n",
    "\n",
    "model.price_mWh = Param(model.hours, within=NonNegativeReals, initialize=data.set_index('Hour')['price_mWh'].to_dict())\n",
    "\n",
    "# Display the model\n",
    "print(model)"
   ],
   "id": "a6d37939c7c177ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "198421df473b3bda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Define Decision Variables with bounds:**\n",
    "This means  x  and  y  are the variables we want to determine, and they must be non-negative (can’t be less than zero)."
   ],
   "id": "e979ea7e6ea5285c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Define the decision variables\n",
    "model.power_transport_vehicles = Var(model.hours, within=NonNegativeReals, bounds=(0, 200))\n",
    "model.set_point = Var(model.hours, within=NonNegativeIntegers, bounds=(18, 25))\n",
    "model.num_active_chiller = Var(model.hours, within=NonNegativeIntegers, bounds=(0, 10))\n",
    "model.standby_power_down = Var(model.hours, within=NonNegativeIntegers, bounds=(0, 1))\n",
    "model.active_printers = Var(model.hours, within=NonNegativeIntegers, bounds=(0, 3))\n",
    "model.active_coffee_machines = Var(model.hours, within=NonNegativeIntegers, bounds=(0, 3))\n",
    "model.num_servers = Var(model.hours, within=NonNegativeIntegers, bounds=(1, 15))\n",
    "model.num_network_switches_poe = Var(model.hours, within=NonNegativeIntegers, bounds=(1, 15))\n",
    "model.num_network_switches_non_poe = Var(model.hours, within=NonNegativeIntegers, bounds=(1, 15))\n",
    "model.num_hdds = Var(model.hours, within=NonNegativeIntegers, bounds=(1, 15))\n",
    "model.num_ssds = Var(model.hours, within=NonNegativeIntegers, bounds=(1, 15))\n",
    "\n",
    "# Define additional decision variables for constraint outcomes\n",
    "model.chiller_energy = Var(model.hours, within=NonNegativeReals)\n",
    "model.data_center_energy = Var(model.hours, within=NonNegativeReals)\n",
    "model.production_energy = Var(model.hours, within=NonNegativeReals)\n",
    "model.uta_energy = Var(model.hours, within=NonNegativeReals)\n",
    "model.office_energy = Var(model.hours, within=NonNegativeReals)\n",
    "\n",
    "# Display the model to check the variables\n",
    "print(model)"
   ],
   "id": "c7db674c9748113d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Define the constraints:**",
   "id": "af2d5c29755be991"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib    \n",
    "\n",
    "chiller_model = joblib.load('equation_modeling/models/chiller_consumption_model.joblib')\n",
    "data_center_model = joblib.load('equation_modeling/models/data_center_consumption_model.joblib')\n",
    "office_model = joblib.load('equation_modeling/models/office_consumption_model.joblib')\n",
    "production_model = joblib.load('equation_modeling/models/production_consumption_model.joblib')\n",
    "uta_model = joblib.load('equation_modeling/models/uta_consumption_model.joblib')"
   ],
   "id": "e8cc2be6989bec88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chiller_intercept = chiller_model['intercept']\n",
    "chiller_coefficients = chiller_model['coefficients']\n",
    "chiller_features = chiller_model['features']\n",
    "\n",
    "# Define the features as Pyomo expressions\n",
    "def heat_index_set_point_diff_expr(model, h):\n",
    "    return model.heat_index[h] - model.set_point[h]\n",
    "\n",
    "# Define the chiller energy consumption constraint\n",
    "def chiller_energy_constraint_rule(model, h):\n",
    "    # Calculate the adjusted energy using the linear regression model\n",
    "    COP_value = 3.0 \n",
    "    \n",
    "    adjusted_energy = ((\n",
    "        chiller_intercept +\n",
    "        chiller_coefficients[0] * heat_index_set_point_diff_expr(model, h) +\n",
    "        chiller_coefficients[1] * model.efficiency_adjusted_power[h] +\n",
    "        chiller_coefficients[2] * model.num_active_chiller[h]\n",
    "    ) / (COP_value * model.efficiency_adjusted_power[h]))\n",
    "    \n",
    "    return model.chiller_energy[h] == adjusted_energy\n",
    "\n",
    "# Add the constraint to the model\n",
    "model.chiller_energy_constraint = Constraint(model.hours, rule=chiller_energy_constraint_rule)"
   ],
   "id": "89840f31bbb64e1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_center_coefficients = data_center_model['coefficients']\n",
    "data_center_features = data_center_model['features']\n",
    "\n",
    "# Define the chiller energy consumption constraint\n",
    "def data_center_constraint_rule(model, h):\n",
    "    \n",
    "    energy = (\n",
    "        data_center_coefficients['server'] * model.num_servers[h] +\n",
    "        data_center_coefficients['network_switch_poe'] * model.num_network_switches_poe[h] +\n",
    "        data_center_coefficients['network_switch_non_poe'] * model.num_network_switches_non_poe[h] +\n",
    "        data_center_coefficients['hdd'] * model.num_hdds[h] +\n",
    "        data_center_coefficients['ssd'] * model.num_ssds[h]\n",
    "    ) \n",
    "    \n",
    "    return model.data_center_energy[h] == energy\n",
    "\n",
    "\n",
    "# Add the constraint to the model\n",
    "model.data_center_energy_constraint = Constraint(model.hours, rule=data_center_constraint_rule)"
   ],
   "id": "c292715aab6dd3ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "production_intercept = production_model['intercept']\n",
    "production_coefficients = production_model['coefficients']\n",
    "production_features = production_model['features']\n",
    "\n",
    "# Define the chiller energy consumption constraint\n",
    "def production_energy_constraint_rule(model, h):\n",
    "    \n",
    "    energy = (\n",
    "        production_intercept +\n",
    "        production_coefficients[0] * model.power_transport_vehicles[h] +\n",
    "        production_coefficients[1] * model.production_schedule[h] +\n",
    "        production_coefficients[2] * model.maintenance_status[h] +\n",
    "        production_coefficients[3] * model.volume_production_waste[h] +\n",
    "        production_coefficients[4] * model.number_of_workers[h]\n",
    "    ) \n",
    "    \n",
    "    return model.production_energy[h] == energy\n",
    "\n",
    "# Add the constraint to the model\n",
    "model.production_energy_constraint = Constraint(model.hours, rule=production_energy_constraint_rule)"
   ],
   "id": "cc4d16bdb47fac50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uta_intercept = uta_model['intercept']\n",
    "uta_coefficients = uta_model['coefficients']\n",
    "uta_features = uta_model['features']\n",
    "\n",
    "# Define the chiller energy consumption constraint\n",
    "def uta_energy_constraint_rule(model, h):\n",
    "    \n",
    "    energy = (\n",
    "        uta_intercept +\n",
    "        uta_coefficients[0] * model.operational_presence[h] +\n",
    "        uta_coefficients[1] * model.fabric_in_chamber[h] +\n",
    "        uta_coefficients[2] * model.testing_schedule[h] +\n",
    "        uta_coefficients[3] * model.workload[h] +\n",
    "        uta_coefficients[4] * model.standby_power_down[h]\n",
    "    ) \n",
    "    \n",
    "    return model.uta_energy[h] == energy\n",
    "\n",
    "# Add the constraint to the model\n",
    "model.uta_energy_constraint = Constraint(model.hours, rule=uta_energy_constraint_rule)"
   ],
   "id": "2d374be7a15fb255",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "office_intercept = office_model['intercept']\n",
    "office_coefficients = office_model['coefficients']\n",
    "office_features = office_model['features']\n",
    "\n",
    "# Define the chiller energy consumption constraint\n",
    "def office_energy_constraint_rule(model, h):\n",
    "    \n",
    "    energy = (\n",
    "        office_intercept +\n",
    "        office_coefficients[0] * model.lightbulbs_active[h] +\n",
    "        office_coefficients[1] * model.active_wall_plugs[h] +\n",
    "        office_coefficients[2] * model.active_computers[h] +\n",
    "        office_coefficients[3] * model.active_printers[h] +\n",
    "        office_coefficients[4] * model.active_coffee_machines[h]\n",
    "    ) \n",
    "    \n",
    "    return model.office_energy[h] == energy\n",
    "\n",
    "# Add the constraint to the model\n",
    "model.office_energy_constraint = Constraint(model.hours, rule=office_energy_constraint_rule)"
   ],
   "id": "bd69734716c38c73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Define Objective Function:**\n",
    "This means we want to minimize the total cost"
   ],
   "id": "45ebdaa2c532763f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Define the objective function\n",
    "def total_cost_rule(model):\n",
    "    return sum(\n",
    "        (model.price_mWh[h] / 1000) * (\n",
    "            model.compressors_energy[h] +\n",
    "            model.technological_centers_energy[h] +\n",
    "            model.chiller_energy[h] +\n",
    "            model.data_center_energy[h] +\n",
    "            model.production_energy[h] +\n",
    "            model.uta_energy[h] +\n",
    "            model.office_energy[h]\n",
    "        ) for h in model.hours\n",
    "    )\n",
    "\n",
    "# Add the objective function to the model\n",
    "model.total_cost = Objective(rule=total_cost_rule, sense=minimize)"
   ],
   "id": "cb72c844f8126a86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Solve the optimization problem:**",
   "id": "edc03fbba26fd40a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solve the model using GLPK\n",
    "solver = SolverFactory('glpk')\n",
    "results = solver.solve(model, tee=True)\n",
    "\n",
    "# Check the solver status\n",
    "if (results.solver.status == 'ok') and (results.solver.termination_condition == 'optimal'):\n",
    "    print(\"Solver found an optimal solution.\")\n",
    "else:\n",
    "    print(\"Solver did not find an optimal solution. Status: \", results.solver.status)\n",
    "\n",
    "# Display the objective function value\n",
    "print(\"Total Cost: \", model.total_cost())\n",
    "\n",
    "# Display the values of the decision variables\n",
    "for h in model.hours:\n",
    "    print(f\"Hour {h}:\")\n",
    "    print(f\"  Power Transport Vehicles: {model.power_transport_vehicles[h].value}\")\n",
    "    print(f\"  Set Point: {model.set_point[h].value}\")\n",
    "    print(f\"  Number of Active Chillers: {model.num_active_chiller[h].value}\")\n",
    "    print(f\"  Standby Power Down: {model.standby_power_down[h].value}\")\n",
    "    print(f\"  Active Printers: {model.active_printers[h].value}\")\n",
    "    print(f\"  Active Coffee Machines: {model.active_coffee_machines[h].value}\")\n",
    "    print(f\"  Number of Servers: {model.num_servers[h].value}\")\n",
    "    print(f\"  Number of Network Switches (PoE): {model.num_network_switches_poe[h].value}\")\n",
    "    print(f\"  Number of Network Switches (Non-PoE): {model.num_network_switches_non_poe[h].value}\")\n",
    "    print(f\"  Number of HDDs: {model.num_hdds[h].value}\")\n",
    "    print(f\"  Number of SSDs: {model.num_ssds[h].value}\")\n",
    "    print(f\"  Chiller Energy: {model.chiller_energy[h].value}\")\n",
    "    print(f\"  Data Center Energy: {model.data_center_energy[h].value}\")\n",
    "    print(f\"  Production Energy: {model.production_energy[h].value}\")\n",
    "    print(f\"  UTA Energy: {model.uta_energy[h].value}\")\n",
    "    print(f\"  Office Energy: {model.office_energy[h].value}\")\n",
    "    print(f\"  Compressors Energy: {model.compressors_energy[h]}\")\n",
    "    print(f\"  Technological Centers Energy: {model.technological_centers_energy[h]}\")\n"
   ],
   "id": "be638b9f1e66f3a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "418fde22d905c66b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DO IT ALL",
   "id": "7a3f8bbd97df0cba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('optimizer/optimizer_input/parameters.csv')\n",
    "data['Time'] = pd.to_datetime(data['Time'])"
   ],
   "id": "e9cb66072a03204c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Create empty dataframes to store the results\n",
    "hourly_results_df = pd.DataFrame()\n",
    "daily_results_df = pd.DataFrame()\n",
    "\n",
    "# Define the start and end dates for the iteration\n",
    "start_date = pd.to_datetime('2023-06-01')\n",
    "end_date = pd.to_datetime('2023-07-01')\n",
    "\n",
    "# Iterate over each day\n",
    "current_date = start_date\n",
    "\n",
    "while current_date < end_date:\n",
    "    # Define the 24-hour period\n",
    "    start_datetime = current_date\n",
    "    end_datetime = current_date + timedelta(days=1)\n",
    "\n",
    "    # Filter the data for the current 24-hour period\n",
    "    filtered_data = data[(data['Time'] >= start_datetime) & (data['Time'] < end_datetime)]\n",
    "    filtered_data = filtered_data.sort_values(by='Time').reset_index(drop=True)\n",
    "\n",
    "    # Initialize the model parameters with filtered data\n",
    "    model.production_schedule = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['production_schedule'].to_dict())\n",
    "    model.maintenance_status = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['maintenance_status'].to_dict())\n",
    "    model.volume_production_waste = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['volume_production_waste'].to_dict())\n",
    "    model.number_of_workers = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['number_of_workers'].to_dict())\n",
    "    model.heat_index = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['heat_index'].to_dict())\n",
    "    model.efficiency_adjusted_power = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['efficiency_adjusted_power'].to_dict())\n",
    "    model.compressors_energy = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['compressor_consumption'].to_dict())\n",
    "    model.operational_presence = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['operational_presence'].to_dict())\n",
    "    model.fabric_in_chamber = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['fabric_in_chamber'].to_dict())\n",
    "    model.testing_schedule = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['testing_schedule'].to_dict())\n",
    "    model.workload = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['workload'].to_dict())\n",
    "    model.technological_centers_energy = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['technological_centers_consumption'].to_dict())\n",
    "    model.lightbulbs_active = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['lightbulbs_active'].to_dict())\n",
    "    model.active_wall_plugs = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['active_wall_plugs'].to_dict())\n",
    "    model.active_computers = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['active_computers'].to_dict())\n",
    "    model.price_mWh = Param(model.hours, within=NonNegativeReals, initialize=filtered_data.set_index(filtered_data.index)['price_mWh'].to_dict())\n",
    "\n",
    "    # Solve the model\n",
    "    solver = SolverFactory('glpk')\n",
    "    results = solver.solve(model, tee=True)\n",
    "\n",
    "    # Check the solver status\n",
    "    if (results.solver.status == 'ok') and (results.solver.termination_condition == 'optimal'):\n",
    "        print(f\"Solver found an optimal solution for {current_date.date()}.\")\n",
    "    else:\n",
    "        print(f\"Solver did not find an optimal solution for {current_date.date()}. Status: {results.solver.status}\")\n",
    "\n",
    "    # Store hourly results\n",
    "    hourly_data = {\n",
    "        'Date': [],\n",
    "        'Hour': [],\n",
    "        'Power Transport Vehicles': [],\n",
    "        'Set Point': [],\n",
    "        'Number of Active Chillers': [],\n",
    "        'Standby Power Down': [],\n",
    "        'Active Printers': [],\n",
    "        'Active Coffee Machines': [],\n",
    "        'Number of Servers': [],\n",
    "        'Number of Network Switches (PoE)': [],\n",
    "        'Number of Network Switches (Non-PoE)': [],\n",
    "        'Number of HDDs': [],\n",
    "        'Number of SSDs': [],\n",
    "        'Compressor Energy': [],\n",
    "        'Technological Centers Energy': [],\n",
    "        'Chiller Energy': [],\n",
    "        'Data Center Energy': [],\n",
    "        'Production Energy': [],\n",
    "        'UTA Energy': [],\n",
    "        'Office Energy': [],\n",
    "        'Total Cost': []\n",
    "    }\n",
    "    for h in model.hours:\n",
    "        hourly_data['Date'].append(current_date)\n",
    "        hourly_data['Hour'].append(h)\n",
    "        hourly_data['Power Transport Vehicles'].append(model.power_transport_vehicles[h].value)\n",
    "        hourly_data['Set Point'].append(model.set_point[h].value)\n",
    "        hourly_data['Number of Active Chillers'].append(model.num_active_chiller[h].value)\n",
    "        hourly_data['Standby Power Down'].append(model.standby_power_down[h].value)\n",
    "        hourly_data['Active Printers'].append(model.active_printers[h].value)\n",
    "        hourly_data['Active Coffee Machines'].append(model.active_coffee_machines[h].value)\n",
    "        hourly_data['Number of Servers'].append(model.num_servers[h].value)\n",
    "        hourly_data['Number of Network Switches (PoE)'].append(model.num_network_switches_poe[h].value)\n",
    "        hourly_data['Number of Network Switches (Non-PoE)'].append(model.num_network_switches_non_poe[h].value)\n",
    "        hourly_data['Number of HDDs'].append(model.num_hdds[h].value)\n",
    "        hourly_data['Number of SSDs'].append(model.num_ssds[h].value)\n",
    "        hourly_data['Compressor Energy'].append(model.compressors_energy[h])\n",
    "        hourly_data['Technological Centers Energy'].append(model.technological_centers_energy[h])\n",
    "        hourly_data['Chiller Energy'].append(model.chiller_energy[h].value)\n",
    "        hourly_data['Data Center Energy'].append(model.data_center_energy[h].value)\n",
    "        hourly_data['Production Energy'].append(model.production_energy[h].value)\n",
    "        hourly_data['UTA Energy'].append(model.uta_energy[h].value)\n",
    "        hourly_data['Office Energy'].append(model.office_energy[h].value)\n",
    "        hourly_data['Total Cost'].append(model.total_cost())\n",
    "\n",
    "    hourly_results_df = pd.concat([hourly_results_df, pd.DataFrame(hourly_data)], ignore_index=True)\n",
    "\n",
    "    # Store daily results\n",
    "    daily_results_df = pd.concat([daily_results_df, pd.DataFrame({\n",
    "        'Date': [current_date],\n",
    "        'Total Cost': [model.total_cost()]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    # Move to the next day\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "\n",
    "# Reset index of the dataframes\n",
    "hourly_results_df.reset_index(drop=True, inplace=True)\n",
    "daily_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get the current datetime in the format YYYYMMDD_HHMMSS\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the files to the new directory with the current datetime\n",
    "hourly_results_df.to_csv(f'optimizer/optimizer_output/{current_datetime}_optimized_hourly_output.csv', index=False)\n",
    "daily_results_df.to_csv(f'optimizer/optimizer_output/{current_datetime}_optimized_daily_output.csv', index=False)\n",
    "\n",
    "print(f'{current_datetime}_optimized_hourly_output.csv output file saved.')\n",
    "print(f'{current_datetime}_optimized_daily_output.csv output file saved.')"
   ],
   "id": "45ae7f0b34d89546",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ground_truth_hourly = pd.read_csv('optimizer/ground_truth/ground_truth_hourly.csv')\n",
    "ground_truth_daily = pd.read_csv('optimizer/ground_truth/ground_truth_daily.csv')\n",
    "\n",
    "evaluate_hourly = pd.merge(hourly_results_df, ground_truth_hourly, left_on=['Date', ' ', 'Hour'], right_on='Time', how='left')\n",
    "evaluate_daily = pd.merge(daily_results_df, ground_truth_daily, on='Time', how='left')\n",
    "\n",
    "evaluate_hourly.to_csv(f'optimizer/optimizer_output/{current_datetime}_evaluate_hourly_output.csv', index=False)\n",
    "evaluate_daily.to_csv(f'optimizer/optimizer_output/{current_datetime}_evaluate_daily_output.csv', index=False)\n",
    "\n"
   ],
   "id": "46209fd8e29614da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4998b1ce24b11095",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
